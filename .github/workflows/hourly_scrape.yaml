name: Hourly CVE Scraper

on:
  schedule:
    - cron: '0 * * * *' 
  workflow_dispatch:      

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install praw requests beautifulsoup4

      - name: Run scraper
        working-directory: ./Reddit_Scraper
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: python reddit_scrapper.py
        
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Commit and push results
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'actions@github.com'
          
          FILE="Reddit_Scraper/reddit_cve_posts.json"
          if [ -f "$FILE" ]; then

            echo "git status:"
            git status
            echo "git diff --stat on reddit_cve_posts.json:"
            git diff --stat "Reddit_Scraper/reddit_cve_posts.json"



            git add "$FILE"
            git commit -m "Update CVE scrape results [bot]" || echo "No changes to commit"
            git remote set-url origin "$REPO_URL"

            echo "Updated remote URL:" 
            git remote -v

            git push
          else
            echo "No results to commit."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_URL: https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}

